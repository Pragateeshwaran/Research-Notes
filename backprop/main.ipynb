{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462246c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae53f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),   \n",
    "    transforms.Normalize((0.1307,), (0.3081,))   \n",
    "])\n",
    " \n",
    "train_data = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276b813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp = torch.exp(x - x.max(dim=1, keepdim=True).values)\n",
    "    return exp / exp.sum(dim=1, keepdim=True)\n",
    "\n",
    "def relu(x):\n",
    "    return torch.clamp(x, min=0)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0cf0390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss: 0.6459, Train Acc: 84.78%\n",
      "Epoch 2/10: Loss: 0.3086, Train Acc: 91.10%\n",
      "Epoch 3/10: Loss: 0.2585, Train Acc: 92.60%\n",
      "Epoch 4/10: Loss: 0.2242, Train Acc: 93.64%\n",
      "Epoch 5/10: Loss: 0.1975, Train Acc: 94.44%\n",
      "Epoch 6/10: Loss: 0.1763, Train Acc: 95.06%\n",
      "Epoch 7/10: Loss: 0.1588, Train Acc: 95.52%\n",
      "Epoch 8/10: Loss: 0.1445, Train Acc: 95.93%\n",
      "Epoch 9/10: Loss: 0.1322, Train Acc: 96.29%\n",
      "Epoch 10/10: Loss: 0.1219, Train Acc: 96.63%\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self): \n",
    "        self.w1 = torch.randn(784, 1024) * 0.01\n",
    "        self.b1 = torch.zeros(1, 1024)\n",
    "        self.w2 = torch.randn(1024, 10) * 0.01\n",
    "        self.b2 = torch.zeros(1, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = x @ self.w1 + self.b1      \n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = self.a1 @ self.w2 + self.b2\n",
    "        self.a2 = softmax(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, x, y_true, learning_rate=0.01):\n",
    "\n",
    "        batch_size = x.shape[0] \n",
    "        y_onehot = torch.zeros_like(self.a2)\n",
    "        y_onehot[range(batch_size), y_true] = 1 \n",
    "\n",
    "        dz2 = self.a2 - y_onehot\n",
    "        dw2 = self.a1.T @ dz2 / batch_size\n",
    "        db2 = dz2.mean(dim=0, keepdim=True) \n",
    "        da1 = dz2 @ self.w2.T\n",
    "        dz1 = da1 * relu_derivative(self.z1)\n",
    "        dw1 = x.T @ dz1 / batch_size\n",
    "        db1 = dz1.mean(dim=0, keepdim=True) \n",
    "        self.w1 -= learning_rate * dw1\n",
    "        self.b1 -= learning_rate * db1\n",
    "        self.w2 -= learning_rate * dw2\n",
    "        self.b2 -= learning_rate * db2\n",
    "    \n",
    "    def loss(self, predictions, targets):\n",
    "        batch_size = predictions.shape[0]\n",
    "        log_prob = -torch.log(predictions[range(batch_size), targets] + 1e-8)\n",
    "        return log_prob.mean()\n",
    "\n",
    "model = Model()\n",
    "epochs=10\n",
    "learning_rate=0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        data = data.view(data.shape[0], -1)\n",
    "            \n",
    "        output = model.forward(data) \n",
    "        loss = model.loss(output, target)\n",
    "        total_loss += loss.item()\n",
    "            \n",
    "        model.backward(data, target, learning_rate) \n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}: Loss: {avg_loss:.4f}, Train Acc: {train_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4925ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337339d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da04b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
